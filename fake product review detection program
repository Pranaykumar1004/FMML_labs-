{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/5Pg8mhV1Lb8a/FpSEVFv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranaykumar1004/FMML_labs-/blob/main/fake%20product%20review%20detection%20program\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fake Product Review Detection using Machine Learning\n",
        "# Libraries import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Step 1: Data Loading\n",
        "print(\"Upload your CSV file containing review data...\")\n",
        "uploaded = files.upload()  # This will prompt the user to upload a file\n",
        "file_name = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(\"\\nDataset Information:\")\n",
        "print(f\"Number of reviews: {df.shape[0]}\")\n",
        "print(f\"Dataset columns: {df.columns.tolist()}\")\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 2: Data Preprocessing\n",
        "print(\"\\nPreprocessing data...\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Assuming 'review_text' is the column containing review text and 'is_fake' is the label\n",
        "# Adjust these column names according to your dataset\n",
        "review_column = 'review_text'  # Change this to match your dataset\n",
        "label_column = 'is_fake'       # Change this to match your dataset\n",
        "\n",
        "# Handle missing values\n",
        "df = df.dropna(subset=[review_column, label_column])\n",
        "\n",
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    if isinstance(text, str):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters, numbers, and extra whitespace\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Remove stopwords\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "        return text\n",
        "    return \"\"\n",
        "\n",
        "# Apply text cleaning\n",
        "df['cleaned_review'] = df[review_column].apply(clean_text)\n",
        "\n",
        "# Remove empty reviews after cleaning\n",
        "df = df[df['cleaned_review'] != \"\"]\n",
        "\n",
        "print(f\"\\nNumber of reviews after cleaning: {df.shape[0]}\")\n",
        "print(\"\\nSample cleaned review:\")\n",
        "print(df['cleaned_review'].iloc[0])\n",
        "\n",
        "# Step 3: Feature Extraction using TF-IDF\n",
        "print(\"\\nExtracting features using TF-IDF...\")\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "# Convert text to TF-IDF features\n",
        "X = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
        "y = df[label_column]\n",
        "\n",
        "print(f\"Feature matrix shape: {X.shape}\")\n",
        "\n",
        "# Step 4: Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Step 5: Model Training and Evaluation\n",
        "\n",
        "# Function to evaluate model performance\n",
        "def evaluate_model(model, X_test, y_test, model_name):\n",
        "    # Predict on test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Display classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return y_pred, cm\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
        "lr_model.fit(X_train, y_train)\n",
        "lr_pred, lr_cm = evaluate_model(lr_model, X_test, y_test, \"Logistic Regression\")\n",
        "\n",
        "# Model 2: Random Forest\n",
        "print(\"\\nTraining Random Forest model...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "rf_pred, rf_cm = evaluate_model(rf_model, X_test, y_test, \"Random Forest\")\n",
        "\n",
        "# Step 6: Visualize confusion matrices\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Logistic Regression confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Genuine', 'Fake'],\n",
        "            yticklabels=['Genuine', 'Fake'])\n",
        "plt.title('Logistic Regression\\nConfusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "# Random Forest confusion matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(rf_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Genuine', 'Fake'],\n",
        "            yticklabels=['Genuine', 'Fake'])\n",
        "plt.title('Random Forest\\nConfusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Compare model performance\n",
        "print(\"\\nModel Comparison:\")\n",
        "models = ['Logistic Regression', 'Random Forest']\n",
        "metrics = {\n",
        "    'Accuracy': [accuracy_score(y_test, lr_pred), accuracy_score(y_test, rf_pred)],\n",
        "    'Precision': [precision_score(y_test, lr_pred, average='weighted'),\n",
        "                 precision_score(y_test, rf_pred, average='weighted')],\n",
        "    'Recall': [recall_score(y_test, lr_pred, average='weighted'),\n",
        "              recall_score(y_test, rf_pred, average='weighted')],\n",
        "    'F1 Score': [f1_score(y_test, lr_pred, average='weighted'),\n",
        "                f1_score(y_test, rf_pred, average='weighted')]\n",
        "}\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics, index=models)\n",
        "print(metrics_df)\n",
        "\n",
        "# Plot model performance comparison\n",
        "plt.figure(figsize=(10, 6))\n",
        "metrics_df.plot(kind='bar', figsize=(12, 6))\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Model')\n",
        "plt.xticks(rotation=0)\n",
        "plt.ylim(0, 1.0)\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nAnalysis complete!\")"
      ],
      "metadata": {
        "id": "fVrOQku8YNZs",
        "outputId": "ba2a40a4-21f9-46f3-8221-2601c6e84bb9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your CSV file containing review data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b54a7444-20c7-454d-9097-ceb946f3ed0a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b54a7444-20c7-454d-9097-ceb946f3ed0a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Product.csv to Amazon_Product (1).csv\n",
            "\n",
            "Dataset Information:\n",
            "Number of reviews: 50000\n",
            "Dataset columns: ['User_ID', 'Product_ID', 'Review_Text', 'Rating', 'Is_Fake', 'Timestamp', 'User_Location', 'Product_Category', 'User_Reputation', 'Review_Length', 'Review_Verified', 'Helpful_Votes', 'Sentiment_Score', 'Device_Used', 'User_Activity_Level', 'Language']\n",
            "\n",
            "Sample data:\n",
            "   User_ID  Product_ID                                        Review_Text  \\\n",
            "0     5724         451          Terrible product. It broke after one use.   \n",
            "1     9974         122  Front position walk less. Tell administration ...   \n",
            "2     2775         163  Kind Fenster darin was. Allein Wasser Vogel gi...   \n",
            "3     6712         201  Explain evidence figure effort. Radio explain ...   \n",
            "4     3320         154    Producto terrible. Se rompió después de un uso.   \n",
            "\n",
            "   Rating  Is_Fake   Timestamp     User_Location Product_Category  \\\n",
            "0       4    False  2023-12-19     Sydney, China      Electronics   \n",
            "1       3     True  2023-04-02     Berlin, Japan             Home   \n",
            "2       2     True  2024-03-03  Tokyo, Australia           Sports   \n",
            "3       3     True  2020-10-17  New York, Canada             Toys   \n",
            "4       4    False  2022-12-15     Mumbai, India             Food   \n",
            "\n",
            "   User_Reputation  Review_Length  Review_Verified  Helpful_Votes  \\\n",
            "0              310              7            False             83   \n",
            "1               45             18            False             90   \n",
            "2              335             24            False              5   \n",
            "3              296             27            False             95   \n",
            "4              398              8             True             61   \n",
            "\n",
            "  Sentiment_Score Device_Used User_Activity_Level Language  \n",
            "0         Neutral      Mobile                High       en  \n",
            "1        Positive      Tablet                High       en  \n",
            "2        Negative      Mobile                High       de  \n",
            "3         Neutral      Mobile              Medium       en  \n",
            "4        Negative      Tablet                 Low       es  \n",
            "\n",
            "Preprocessing data...\n",
            "\n",
            "Missing values in each column:\n",
            "User_ID                0\n",
            "Product_ID             0\n",
            "Review_Text            0\n",
            "Rating                 0\n",
            "Is_Fake                0\n",
            "Timestamp              0\n",
            "User_Location          0\n",
            "Product_Category       0\n",
            "User_Reputation        0\n",
            "Review_Length          0\n",
            "Review_Verified        0\n",
            "Helpful_Votes          0\n",
            "Sentiment_Score        0\n",
            "Device_Used            0\n",
            "User_Activity_Level    0\n",
            "Language               0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "['review_text', 'is_fake']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-831ba6a7d21b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreview_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# Text cleaning function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdropna\u001b[0;34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[0m\n\u001b[1;32m   6668\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6670\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6671\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ['review_text', 'is_fake']"
          ]
        }
      ]
    }
  ]
}